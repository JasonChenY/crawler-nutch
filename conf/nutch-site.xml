<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
<property>
 <name>storage.data.store.class</name>
 <value>org.apache.gora.hbase.store.HBaseStore</value>
 <description>Default class for storing data</description>
</property>

<property>  
 <name>http.agent.name</name>  
 <value>My Nutch Spider</value>  
</property>  

<property>
  <name>fetcher.threads.fetch</name>
  <value>1</value>
</property>

<property>
  <name>fetcher.threads.per.queue</name>
  <value>1</value>
  <description>This number is the maximum number of threads that
    should be allowed to access a queue at one time. Setting it to
    a value > 1 will cause the Crawl-Delay value from robots.txt to
    be ignored and the value of fetcher.server.min.delay to be used
    as a delay between successive requests to the same server instead
    of fetcher.server.delay.
   </description>
</property>

<property>
  <name>fetcher.verbose</name>
  <value>true</value>
</property>

<property>
  <name>db.max.outlinks.per.page</name>
  <value>-1</value>
  <description>Dont care about how many outlinks, this is decided basing on the page list, job list</description>
</property>

<property>
  <name>plugin.includes</name>
  <value>protocol-httpclient4|parse-company|index-(basic|anchor)|urlnormalizer-pass|scoring-opic|indexer-solr</value>
  <description>dont need urlfilter-regex</description>
</property>

<property>
  <name>db.ignore.external.links</name>
  <value>true</value>
</property>

<property>
  <name>company.schema.dir</name>
  <value>/sdk/tools/apache-nutch-2.3/localrepo/schemas</value>
</property>

<property>
  <name>file.content.limit</name>
  <value>-1</value>
  <description>Dont care about the content lenght, best effort!</description>
</property>

</configuration>

